<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds">

    <!--组件名称 自行修改-->
    <property name="COMPONENT_ID" value="kafka-producer"/>
    <!--服务名称 自行修改-->
    <property name="SEGMENT_ID" value="kafka-producer"/>
    <!--日志文件输出路径-->
    <property name="LOG_HOME" value="logs"/>
    <!-- 本地测试时日志文件路径 -->
    <!-- <property name="LOG_HOME" value="./logs/${SEGMENT_ID}/" /> -->
    <!-- 日志编码 -->
    <property name="log.charset" value="UTF-8"/>
    <!-- 日志文件大小,超过这个大小将重新创建,可以根据实际情况调整-->
    <property name="log.max.size" value="25MB"/>
    <!--debug 文件 设置为100MB-->
    <property name="log.debug.max.size" value="100MB"/>
    <!-- 日志最大循环保留个数，可以根据实际情况调整-->
    <property name="log.max.index" value="10"/>

    <!-- 日志格式-->
    <!--控制台-->
    <property name="STDOUT_LOG_PATTERN"
              value="%d{yyyy-MM-dd'T'HH:mm:ss.SSSXXX} %5p ${COMPONENT_ID}.${SEGMENT_ID} [%thread] [%logger{80}:%line] %X{X-HIK_TRACE:-} %X{X-HIK_ERROR_CODE:-} - %msg %n "/>
    <!--文件-->
    <property name="FILE_LOG_PATTERN"
              value="%d{yyyy-MM-dd'T'HH:mm:ss.SSSXXX} %5p ${COMPONENT_ID}.${SEGMENT_ID} [%thread] [%logger{50}:%line] %X{X-HIK_TRACE:-} %X{X-HIK_ERROR_CODE:-} - %msg %n "/>
    <!--other-->
    <property name="OTHER_PATTERN"
              value=" %d{yyyy-MM-dd'T'HH:mm:ss.SSSXXX} %5p ${COMPONENT_ID}.${SEGMENT_ID} [%thread] [%logger{50}:%line] %X{X-HIK_TRACE:-} %X{X-HIK_ERROR_CODE:-} - %msg %n "/>

    <!--操作日志-->
    <property name="BUSINESS_FILE_LOG_PATTERN" value="%d{yyyy-MM-dd'T'HH:mm:ss.SSSXXX} - %msg %n"/>
    <!-- 追踪日志-->
    <property name="TRACE_FILE_LOG_PATTERN"
              value="%d{yyyy-MM-dd'T'HH:mm:ss.SSSXXX} [%thread] [%logger{50}:%line] - %msg%n"/>

    <!-- 控制台Appender -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>DEBUG</level>
        </filter>
        <encoder>
            <pattern>${STDOUT_LOG_PATTERN}</pattern>
            <charset>${log.charset}</charset>
        </encoder>
    </appender>

    <!--debug 文件 配置-->
    <appender name="FILE-debug" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>TRACE</level>
        </filter>
        <File>${LOG_HOME}/${COMPONENT_ID}.${SEGMENT_ID}.debug.log</File>
        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <!-- debug文件大小设置为100M, 再压缩 -->
            <MaxFileSize>${log.debug.max.size}</MaxFileSize>
        </triggeringPolicy>
        <encoder>
            <pattern>${FILE_LOG_PATTERN}</pattern>
            <charset>${log.charset}</charset>
        </encoder>
    </appender>
    <!-- debug 文件 配置 结束-->

    <!-- error 文件配置-->
    <appender name="FILE-error" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>ERROR</level>
        </filter>
        <File>${LOG_HOME}/${COMPONENT_ID}.${SEGMENT_ID}.error.log</File>
        <triggeringPolicy
                class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <MaxFileSize>${log.max.size}</MaxFileSize>
        </triggeringPolicy>
        <encoder>
            <pattern>${FILE_LOG_PATTERN}</pattern>
            <charset>${log.charset}</charset>
        </encoder>
    </appender>
    <!-- error 文件配置 结束-->


    <!-- 非组件打印的日志,error和warn无法携带错误码, 输出到OTHER文件中 -->
    <!--没有配置logger 使用root的配置-->
    <appender name="OTHER" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>WARN</level>
        </filter>
        <File>${LOG_HOME}/${COMPONENT_ID}.${SEGMENT_ID}.other.log</File>
        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <MaxFileSize>${log.max.size}</MaxFileSize>
        </triggeringPolicy>
        <encoder>
            <pattern>${OTHER_PATTERN}</pattern>
            <charset>${log.charset}</charset>
        </encoder>
    </appender>
    <!--logger 配置 -->

    <!-- 定义操作日志向哪个appender写入日志-->
    <!--additivity 代表此日志是否会打印在root配置的appender里面-->
    <logger name="com.aries.jc.common.boot.operationlog.interceptor.OperationLogInterceptor" level="INFO"
            additivity="false">
        <appender-ref ref="BUS"/>
        <appender-ref ref="STDOUT"/>
    </logger>

    <!--定时任务打印操作日志的特殊处理-->
    <logger name="com.aries.jc.common.boot.operationlog.util.OperateLogScheduled" level="INFO" additivity="false">
        <appender-ref ref="BUS"/>
        <appender-ref ref="STDOUT"/>
    </logger>

    <!--定义追踪日志向哪个appender写入日志-->
    <logger name="com.aries.jc.common.boot.tracer.log.AriesTracerSlf4jLog" level="INFO" additivity="false">
        <appender-ref ref="DTS"/>
        <appender-ref ref="STDOUT"/>
    </logger>

    <!-- 本地测试时，可以修改level 以便打印debug日志 -->
    <!--定义com. 包下的类日志向哪个appender写入日志-->
    <logger name="com.vv.java.demo.kafka.producer" level="debug" additivity="false">
        <appender-ref ref="FILE-debug"/>
        <appender-ref ref="FILE-error"/>
        <appender-ref ref="STDOUT"/>
    </logger>

    <!--不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
    <!--更改默认的队列的深度,该值会影响性能.默认值为256 -->
    <!--添加附加的appender,最多只能添加一个 -->
    <appender name="file.async" class="ch.qos.logback.classic.AsyncAppender">
        <discardingThreshold>0</discardingThreshold>
        <queueSize>256</queueSize>
        <includeCallerData>true</includeCallerData>
        <appender-ref ref="FILE-debug"/>
    </appender>

    <!--自定义项， 重要程度不高、打印频繁的日志来源,日志级别设高，避免频繁打印-->
    <!--<logger name="org.apache.zookeeper.ClientCnxn" level="ERROR" />-->
    <!--<logger name="org.springframework.boot" level="WARN" />-->
    <!--<logger name="org.springframework.boot.web.filter" level="ERROR" />-->

    <!--默认配置 非组件打印的日志采用warn以上级别，并输出到other文件中 -->
    <root level="WARN">
        <appender-ref ref="OTHER"/>
        <appender-ref ref="STDOUT"/>
    </root>

</configuration>